{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = torch.load('./model-v1/80000/mp_rank_00_model_states.pt', map_location='cpu')\n",
    "m1 = torch.load('./model-v1/80000/mp_rank_01_model_states.pt', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(model, name):\n",
    "    for n, w in model['module'].items():\n",
    "        if name == n:\n",
    "            return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeddings.weight torch.Size([15000, 2560])\n",
      "position_embeddings.weight torch.Size([1024, 2560])\n",
      "transformer.layers.0.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.0.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.0.attention.query_key_value.weight torch.Size([3840, 2560])\n",
      "transformer.layers.0.attention.query_key_value.bias torch.Size([3840])\n",
      "transformer.layers.0.attention.dense.weight torch.Size([2560, 1280])\n",
      "transformer.layers.0.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.0.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.0.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.0.mlp.dense_h_to_4h.weight torch.Size([5120, 2560])\n",
      "transformer.layers.0.mlp.dense_h_to_4h.bias torch.Size([5120])\n",
      "transformer.layers.0.mlp.dense_4h_to_h.weight torch.Size([2560, 5120])\n",
      "transformer.layers.0.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.final_layernorm.weight torch.Size([2560])\n",
      "transformer.final_layernorm.bias torch.Size([2560])\n"
     ]
    }
   ],
   "source": [
    "for n, w in m0['module'].items():\n",
    "    if '.layers.' in n:\n",
    "        if '.layers.0.' in n:\n",
    "            print(n, w.shape)\n",
    "    else:\n",
    "        print(n, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 30000)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Config, TFGPT2LMHeadModel\n",
    "\n",
    "gpt2_config = GPT2Config(\n",
    "    vocab_size=30000,\n",
    "    n_positions=1024,\n",
    "    n_ctx=1024,\n",
    "    n_embd=2560,\n",
    "    n_layer=32,\n",
    "    n_head=32,\n",
    "    pad_token_id=0,\n",
    ")\n",
    "gpt2_model = TFGPT2LMHeadModel(gpt2_config)\n",
    "loss = gpt2_model.compute_loss\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "# metric = Mymetrice('accuracy')\n",
    "\n",
    "gpt2_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=[loss, *[None] * gpt2_model.config.n_layer],\n",
    "    metrics=[metric]\n",
    ")\n",
    "input = tf.constant([[1, 2]])\n",
    "out = gpt2_model(input)[0]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfgp_t2lm_head_model/transformer/wte/weight:0 (30000, 2560)\n",
      "tfgp_t2lm_head_model/transformer/wpe/embeddings:0 (1024, 2560)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/ln_1/gamma:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/ln_1/beta:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/attn/c_attn/weight:0 (2560, 7680)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/attn/c_attn/bias:0 (1, 7680)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/attn/c_proj/weight:0 (2560, 2560)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/attn/c_proj/bias:0 (1, 2560)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/ln_2/gamma:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/ln_2/beta:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/mlp/c_fc/weight:0 (2560, 10240)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/mlp/c_fc/bias:0 (1, 10240)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/mlp/c_proj/weight:0 (10240, 2560)\n",
      "tfgp_t2lm_head_model/transformer/h_._0/mlp/c_proj/bias:0 (1, 2560)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/ln_1/gamma:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/ln_1/beta:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/attn/c_attn/weight:0 (2560, 7680)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/attn/c_attn/bias:0 (1, 7680)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/attn/c_proj/weight:0 (2560, 2560)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/attn/c_proj/bias:0 (1, 2560)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/ln_2/gamma:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/ln_2/beta:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/mlp/c_fc/weight:0 (2560, 10240)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/mlp/c_fc/bias:0 (1, 10240)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/mlp/c_proj/weight:0 (10240, 2560)\n",
      "tfgp_t2lm_head_model/transformer/h_._31/mlp/c_proj/bias:0 (1, 2560)\n",
      "tfgp_t2lm_head_model/transformer/ln_f/gamma:0 (2560,)\n",
      "tfgp_t2lm_head_model/transformer/ln_f/beta:0 (2560,)\n"
     ]
    }
   ],
   "source": [
    "for w in gpt2_model.weights:\n",
    "    if 'h_._' in w.name:\n",
    "        if 'h_._0' in w.name or 'h_._31' in w.name:\n",
    "            print(w.name, w.shape)\n",
    "    else:\n",
    "        print(w.name, w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "for w in gpt2_model.weights:\n",
    "    num_layer = 0\n",
    "    if 'h_._' in w.name:\n",
    "        num_layer = re.findall(r'transformer/h_._(\\d+)', w.name)[0]\n",
    "\n",
    "    if 'transformer/wte/weight:0' in w.name:\n",
    "        w0 = get_weight(m0, f'word_embeddings.weight')\n",
    "        w1 = get_weight(m1, f'word_embeddings.weight')\n",
    "        w = np.concatenate([w0.numpy(), w1.numpy()])\n",
    "        assert w.shape == (30000, 2560)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/wte/weight')\n",
    "    elif 'transformer/wpe/embeddings:0' in w.name:\n",
    "        w0 = get_weight(m0, f'position_embeddings.weight')\n",
    "        ｗ = w0.numpy()\n",
    "        assert w.shape == (1024, 2560)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/wpe/embeddings')\n",
    "    elif 'ln_1/gamma:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.input_layernorm.weight')\n",
    "        w = w0.numpy()\n",
    "        assert w.shape == (2560, )\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} ln_1/gamma')\n",
    "    elif 'ln_1/beta:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.input_layernorm.bias')\n",
    "        w = w0.numpy()\n",
    "        assert w.shape == (2560, )\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} ln_1/beta')\n",
    "    elif 'attn/c_attn/weight:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.attention.query_key_value.weight')\n",
    "        w1 = get_weight(m1, f'transformer.layers.{num_layer}.attention.query_key_value.weight')\n",
    "        w0 = w0.numpy()\n",
    "        w1 = w1.numpy()\n",
    "        q0 = w0[:1280, :]\n",
    "        q1 = w1[:1280, :]\n",
    "        k0 = w0[1280:1280 * 2, :]\n",
    "        k1 = w1[1280:1280 * 2, :]\n",
    "        v0 = w0[1280 * 2:, :]\n",
    "        v1 = w1[1280 * 2:, :]\n",
    "        w = np.concatenate([q0, q1, k0, k1, v0, v1])\n",
    "        assert w.shape == (7680, 2560)\n",
    "        w = np.transpose(w)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} c_attn/weight')\n",
    "    elif 'attn/c_attn/bias:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.attention.query_key_value.bias')\n",
    "        w1 = get_weight(m1, f'transformer.layers.{num_layer}.attention.query_key_value.bias')\n",
    "        w = np.concatenate([w0.numpy(), w1.numpy()])\n",
    "        w = np.transpose(w)\n",
    "        w = w.reshape(1, 7680)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} c_attn/bias')\n",
    "    elif 'attn/c_proj/weight:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.attention.dense.weight')\n",
    "        w1 = get_weight(m1, f'transformer.layers.{num_layer}.attention.dense.weight')\n",
    "        w = np.concatenate([w0.numpy(), w1.numpy()], axis=-1)\n",
    "        assert w.shape == (2560, 2560)\n",
    "        w = np.transpose(w)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} c_proj/weight')\n",
    "    elif 'attn/c_proj/bias:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.attention.dense.bias')\n",
    "        w = w0.numpy()\n",
    "        assert w.shape == (2560, )\n",
    "        w = w.reshape(1, 2560)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} c_proj/bias')\n",
    "    elif 'ln_2/gamma:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.post_attention_layernorm.weight')\n",
    "        w = w0.numpy()\n",
    "        assert w.shape == (2560, )\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} ln_2/gamma')\n",
    "    elif 'ln_2/beta:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.post_attention_layernorm.bias')\n",
    "        w = w0.numpy()\n",
    "        assert w.shape == (2560, )\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} ln_2/beta')\n",
    "    elif 'mlp/c_fc/weight:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.mlp.dense_h_to_4h.weight')\n",
    "        w1 = get_weight(m1, f'transformer.layers.{num_layer}.mlp.dense_h_to_4h.weight')\n",
    "        w = np.concatenate([w0.numpy(), w1.numpy()])\n",
    "        assert w.shape == (10240, 2560)\n",
    "        w = np.transpose(w)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} mlp/c_fc/weight')\n",
    "    elif 'mlp/c_fc/bias:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.mlp.dense_h_to_4h.bias')\n",
    "        w1 = get_weight(m1, f'transformer.layers.{num_layer}.mlp.dense_h_to_4h.bias')\n",
    "        w = np.concatenate([w0.numpy(), w1.numpy()])\n",
    "        assert w.shape == (10240, )\n",
    "        w = w.reshape(1, 10240)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} mlp/c_fc/bias')\n",
    "    elif 'mlp/c_proj/weight:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.mlp.dense_4h_to_h.weight')\n",
    "        w1 = get_weight(m1, f'transformer.layers.{num_layer}.mlp.dense_4h_to_h.weight')\n",
    "        w = np.concatenate([w0.numpy(), w1.numpy()], axis=-1)\n",
    "        assert w.shape == (2560, 10240)\n",
    "        w = np.transpose(w)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} mlp/c_proj/weight')\n",
    "    elif 'mlp/c_proj/bias:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.layers.{num_layer}.mlp.dense_4h_to_h.bias')\n",
    "        w = w0.numpy()\n",
    "        assert w.shape == (2560, )\n",
    "        w = w.reshape(1, 2560)\n",
    "        new_weights.append(w)\n",
    "        print(f'setting layer {num_layer} mlp/c_proj/bias')\n",
    "    elif 'transformer/ln_f/gamma:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.final_layernorm.weight')\n",
    "        ｗ = w0.numpy()\n",
    "        assert w.shape == (2560, )\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/ln_f/gamma')\n",
    "    elif 'transformer/ln_f/beta:0' in w.name:\n",
    "        w0 = get_weight(m0, f'transformer.final_layernorm.bias')\n",
    "        ｗ = w0.numpy()\n",
    "        assert w.shape == (2560, )\n",
    "        new_weights.append(w)\n",
    "        print(f'setting transformer/ln_f/beta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_tokenizer import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer(\n",
    "    'CPM-Generate/bpe_3w_new/vocab.json',\n",
    "    'CPM-Generate/bpe_3w_new/merges.txt',\n",
    "    model_file='CPM-Generate/bpe_3w_new/chinese_vocab.model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[837, 259, 497, 11366, 8]\n",
      "0 今天天气不错\n",
      "[837, 259, 497, 11366, 8, 9]\n",
      "1 今天天气不错,\n",
      "[837, 259, 497, 11366, 8, 9, 2187]\n",
      "2 今天天气不错,心情\n",
      "[837, 259, 497, 11366, 8, 9, 2187, 26]\n",
      "3 今天天气不错,心情也\n",
      "[837, 259, 497, 11366, 8, 9, 2187, 26, 788]\n",
      "4 今天天气不错,心情也不错\n",
      "[837, 259, 497, 11366, 8, 9, 2187, 26, 788, 8]\n",
      "5 今天天气不错,心情也不错\n",
      "[837, 259, 497, 11366, 8, 9, 2187, 26, 788, 8, 9]\n",
      "6 今天天气不错,心情也不错,\n",
      "[837, 259, 497, 11366, 8, 9, 2187, 26, 788, 8, 9, 29]\n",
      "7 今天天气不错,心情也不错,就\n",
      "[837, 259, 497, 11366, 8, 9, 2187, 26, 788, 8, 9, 29, 84]\n",
      "8 今天天气不错,心情也不错,就想\n",
      "[837, 259, 497, 11366, 8, 9, 2187, 26, 788, 8, 9, 29, 84, 197]\n",
      "9 今天天气不错,心情也不错,就想着\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode('今天天气不错')\n",
    "\n",
    "for i in range(10):\n",
    "    output = model(tf.constant([ids]))\n",
    "    nid = np.argmax(output[0][0, -1])\n",
    "    ids += [nid]\n",
    "    print(ids)\n",
    "    print(i, tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model.save_pretrained('/data2/CPM-TF/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, TFGPT2LMHeadModel, TextGenerationPipeline\n",
    "\n",
    "\n",
    "tokenizer = XLNetTokenizer('CPM-Generate/bpe_3w_new/chinese_vocab.model', add_special_token=False)\n",
    "\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"/data2/CPM-TF/models\")\n",
    "\n",
    "text_generater = TextGenerationPipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '今天天气不错 , 心情 也 不错 , 就 想着 出去 散散心 ,'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '今天天气不错 , 心情舒畅 , 于是 就 想着 吃点 啥 ,'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '修真者到了元婴期之后经天地元气重筑的肉身 , 因为 元婴 的 境界 , 是 “ 物我两忘 ” , 物我两忘 , 就是 物我两忘 , 物我'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(text_generater('今天天气不错', max_length=20))\n",
    "display(text_generater('今天天气不错', max_length=20, do_sample=True, top_k=10, top_p=0.95))\n",
    "display(text_generater('修真者到了元婴期之后经天地元气重筑的肉身', max_length=60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
